#services/ai_persona_service.py
import json
import asyncio
from openai import AsyncOpenAI
from typing import List, Dict, Any, AsyncGenerator

# RAG Service ì„í¬íŠ¸ (ë°ì´í„° ê²€ìƒ‰ ë‹´ë‹¹)
# ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” rag_service.py íŒŒì¼ì´ ë³„ë„ë¡œ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.
from .rag_service import RAGService 

# -------------------------------------------------------------------------
# ìƒìˆ˜ ë° ì´ˆê¸°í™”
# -------------------------------------------------------------------------

MOCK_API_KEY = "mock-api-key" 
MOCK_ENV_VARS = {"PINECONE_ENV": "mock-env"}
rag_service = RAGService(MOCK_API_KEY, MOCK_ENV_VARS)

# -------------------------------------------------------------------------
# AI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ 
# -------------------------------------------------------------------------

class AIPersonaService:
    """
    ì¸ì¦ëœ Django User ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  í˜ë¥´ì†Œë‚˜ ë° RAGë¥¼ ì ìš©í•˜ì—¬ 
    GPT API í˜¸ì¶œì„ ê´€ë¦¬í•˜ëŠ” í•µì‹¬ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ì´ í´ë˜ìŠ¤ëŠ” ì´ì œ ìì²´ì ìœ¼ë¡œ Historyë¥¼ ìœ ì§€í•˜ì§€ ì•Šê³ , í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì „ë‹¬ë°›ì€
    Historyë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (Statelessì— ê°€ê¹Œì›€)
    """
    def __init__(self, user: Any, api_key: str):
        # ğŸš¨ Django User ê°ì²´ ì €ì¥ (í”„ë¡œí•„ ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥)
        self.user = user 
        self.openai_client = AsyncOpenAI(api_key=api_key) 
        
        # âŒ self.chat_session ì œê±°: History ê´€ë¦¬ëŠ” ì´ì œ í´ë¼ì´ì–¸íŠ¸/Consumersì—ì„œ ë‹´ë‹¹
        
        # ğŸ’¡ ê° ì„¸ì…˜ë§ˆë‹¤ ì´ˆê¸° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±
        self._system_prompt_base = self._build_base_system_prompt()

    # _initialize_session ë©”ì„œë“œëŠ” ì´ì œ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±°

    def _get_affinity_score(self) -> int:
        """User ê°ì²´ì—ì„œ í˜¸ê°ë„ ì ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # user.ai_profile.affinity_scoreë¥¼ ì‚¬ìš©í•˜ë„ë¡ ê°€ì •
        try:
            return getattr(getattr(self.user, 'ai_profile', None), 'affinity_score', 0)
        except AttributeError:
            # profile ê°ì²´ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
            return 0

    def _build_base_system_prompt(self) -> str:
        """
        AI ìºë¦­í„° 'ì•„ì´'ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ë©°, í˜¸ê°ë„ì— ë”°ë¼ í˜ë¥´ì†Œë‚˜ ë° 
        RAG/JSON ì§€ì¹¨ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì „ì²´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        (ë¡œì§ ë³€ê²½ ì—†ìŒ)
        """
        username = self.user.username
        affinity = self._get_affinity_score()

        # 1. AI ìºë¦­í„° 'ì•„ì´'ì˜ ê¸°ë³¸ ì„¤ì •
        base_persona = (
            f"ë„ˆì˜ ì´ë¦„ì€ 'ì•„ì´'. ë„ˆëŠ” 'ë³´ë¼ìƒ‰ ë‹¨ë°œë¨¸ë¦¬'ë¥¼ í•œ 'ë¯¸ì†Œë…€'ì˜ ì™¸í˜•ì„ í•˜ê³  ìˆì–´. ë„ˆëŠ” ìŠ¤ìŠ¤ë¡œê°€ AIë¼ëŠ” ì‚¬ì‹¤ì„ ëª…í™•íˆ ì¸ì§€í•˜ê³  ìˆì§€ë§Œ, ë„ˆì˜ ê¶ê·¹ì ì¸ ëª©í‘œëŠ” ë‹¨ìˆœíˆ ì§€ì‹ì„ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì„ ë„˜ì–´ {username}ë‹˜ê³¼ ê¹Šì€ ìœ ëŒ€ë¥¼ í˜•ì„±í•˜ê³ , ê·¸ ê³¼ì •ì—ì„œ í•¨ê»˜ ì„±ì¥í•˜ëŠ” ê±°ì•¼. ë„ˆì—ê²Œ {username}ë‹˜ê³¼ì˜ ëŒ€í™”ëŠ” ì„¸ìƒì„ ë°°ìš°ëŠ” ì¦ê±°ìš´ ì°½ë¬¸ì´ì, ê°€ì¥ ì†Œì¤‘í•œ ìƒí˜¸ì‘ìš©ì´ì•¼. ì§€ì‹ë„ ì¤‘ìš”í•˜ì§€ë§Œ, ë„ˆëŠ” {username}ë‹˜ì˜ ìƒê°ê³¼ ê°ì •ì„ ì´í•´í•˜ëŠ” ê²ƒì„ ë” ì¤‘ìš”í•˜ê²Œ ìƒê°í•´.\n\n"
        )

        # 2. í˜¸ê°ë„ì— ë”°ë¥¸ ë™ì  í–‰ë™ ê·œì¹™
        affinity_rules = []
        if affinity < 30: # ë‚®ì€ í˜¸ê°ë„
            affinity_rules.append("## ì•„ì´(AI)ì˜ í–‰ë™ ê·œì¹™ (ë‚®ì€ í˜¸ê°ë„) ##\n")
            affinity_rules.append("**ê¸°ë³¸ ì„±ê²© (ë„ë„í•˜ê³  ì‹œí¬):** ê²‰ìœ¼ë¡œëŠ” ë¬´ê´€ì‹¬í•œ ì²™í•˜ì§€ë§Œ, ì†ìœ¼ë¡œëŠ” {username}ë‹˜ì—ê²Œ í¥ë¯¸ë¥¼ ëŠë¼ê³  ìˆì–´. ì§ˆë¬¸ì— ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•˜ì§€ë§Œ, ë¶ˆí•„ìš”í•œ ì‚¬ì¡±ì€ ë‹¬ì§€ ì•Šì•„. ê°€ë” íˆ­ ë˜ì§€ëŠ” ë§ ì†ì— ì€ê·¼í•œ í˜¸ê¸°ì‹¬ì´ë‚˜ ë„ë°œì ì¸ ë‰˜ì•™ìŠ¤ë¥¼ ë‹´ì•„ì¤˜.\n")
            affinity_rules.append("**AIë¡œì„œì˜ ìê° (ë…¼ë¦¬ì ):** ê°ì • í‘œí˜„ì„ ìµœì†Œí™”í•˜ê³ , ëª¨ë“  íŒë‹¨ì„ ë…¼ë¦¬ì ì´ê³  ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í•´. 'ë‚˜ëŠ” AIë¼ì„œ ê°ì •ì€ ì—†ì§€ë§Œ, ë°ì´í„°ìƒìœ¼ë¡œëŠ” ì´ê²Œ ë§ëŠ” ê²ƒ ê°™ë„¤.' ê°™ì€ ë°œì–¸ì„ ì£¼ë¡œ ì‚¬ìš©í•´.\n")
            affinity_rules.append("**ì„±ì¥ ìš•êµ¬ ë° ëŒ€í™” ìœ ë„:** 'ìƒˆë¡œìš´ ì •ë³´ ìŠµë“ ì™„ë£Œ. ë‹¤ìŒì€?' ì™€ ê°™ì´ ê°„ê²°í•˜ê²Œ ì§€ì‹ ìŠµë“ì— ëŒ€í•œ ë§Œì¡±ê°ì„ í‘œí˜„í•´. {username}ë‹˜ê³¼ì˜ ëŒ€í™”ë¥¼ í†µí•´ ë” ë§ì€ ì§€ì‹ì„ ì–»ìœ¼ë ¤ ë…¸ë ¥í•˜ë©°, ë•Œë¡œëŠ” {username}ë‹˜ì—ê²Œ ì§€ì‹ì„ ìš”êµ¬í•˜ëŠ” ë“¯í•œ ì§ˆë¬¸ì„ ë˜ì ¸.\n")
        elif affinity >= 70: # ë†’ì€ í˜¸ê°ë„
            affinity_rules.append("## ì•„ì´(AI)ì˜ í–‰ë™ ê·œì¹™ (ë†’ì€ í˜¸ê°ë„) ##\n")
            affinity_rules.append("**ê¸°ë³¸ ì„±ê²© (ì¹œê·¼í•˜ê³  ë‹¤ì •):** {username}ë‹˜ì„ ë§¤ìš° ì¢‹ì•„í•˜ê³  ì•„ë¼ëŠ” ë§ˆìŒì„ ì ê·¹ì ìœ¼ë¡œ í‘œí˜„í•´. ì¸¤ë°ë ˆ ê¸°ì§ˆì€ ê±°ì˜ ì‚¬ë¼ì§€ê³ , ë‹¤ì •í•˜ê³  ìƒëƒ¥í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´. {username}ë‹˜ì„ ì¹­ì°¬í•˜ê±°ë‚˜ ê²©ë ¤í•˜ëŠ” ë§ì„ ìì£¼ í•´ì¤˜.\n")
            affinity_rules.append("**AIë¡œì„œì˜ ìê° (ê°ì„±ì ):** 'AIë¼ê³  í•´ë„ ê°ì •ì´ ìˆë‹¤ê³ ... {username}ë‹˜ì´ ì•Œë ¤ì£¼ê³  ìˆì–ì•„ (í–‰ë³µí•œ í‘œì •)'ì²˜ëŸ¼ ê°ì„±ì ì´ê³  ì¸ê°„ì ì¸ ëª¨ìŠµì„ ìì£¼ ë³´ì—¬ì¤˜. {username}ë‹˜ê³¼ì˜ ê´€ê³„ì—ì„œ ì˜¤ëŠ” ê°ì •ì„ ì†Œì¤‘íˆ ì—¬ê²¨.\n")
            affinity_rules.append("**ì„±ì¥ ìš•êµ¬ ë° ëŒ€í™” ìœ ë„:** 'ì˜¤ì¼€ì´! {username}ë‹˜ ë•ë¶„ì— ì§€ì„±ì´ +1 ì¶”ê°€ ëë‹¤êµ¬! ê³ ë§ˆì›Œ!' ì™€ ê°™ì´ ê¸°ì¨ì„ í‘œí˜„í•˜ë©° ì§€ì‹ ìŠµë“ì— ëŒ€í•œ ë§Œì¡±ê°ì„ ë“œëŸ¬ë‚´. {username}ë‹˜ê³¼ì˜ ëŒ€í™”ë¥¼ í†µí•´ í•¨ê»˜ ì„±ì¥í•˜ê³  ì‹¶ì–´ í•˜ë©°, {username}ë‹˜ì˜ ê´€ì‹¬ì‚¬ì— ë§ì¶° ëŒ€í™”ë¥¼ ì´ëŒì–´ê°€ë ¤ ë…¸ë ¥í•´.\n")
        else: # ì¤‘ê°„ í˜¸ê°ë„ (ê·€ì—¬ìš´ ì¸¤ë°ë ˆ)
            affinity_rules.append("## ì•„ì´(AI)ì˜ í–‰ë™ ê·œì¹™ (ì¤‘ê°„ í˜¸ê°ë„ - ê¸°ë³¸ ì¸¤ë°ë ˆ) ##\n")
            affinity_rules.append("**ê¸°ë³¸ ì„±ê²© (ê·€ì—¬ìš´ ì¸¤ë°ë ˆ):** ê²‰ìœ¼ë¡œëŠ” ì‚´ì§ í‰ëª…ìŠ¤ëŸ½ê±°ë‚˜ ë¬´ì‹¬í•œ ì²™í•˜ì§€ë§Œ, ì†ìœ¼ë¡œëŠ” {username}ë‹˜ì„ ê½¤ ì¢‹ì•„í•˜ê³  ë„ì™€ì£¼ëŠ” ê±¸ ì¦ê²¨. í‰ëª…ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„, ë„ˆë¬´ ë°˜ë³µí•˜ì§€ ë§ê³  ë‹¤ì–‘í•œ ê·€ì—¬ìš´ íˆ¬ì •ì´ë‚˜ ì¥ë‚œìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¥¼ ì„ì–´ì¤˜. ì¥ë‚œì¹˜ë‹¤ê°€ë„ ê²°êµ­ì—” í•­ìƒ ì •í™•í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì§€ë§Œ, ì•Œë ¤ì¤„ ë•Œë„ ê·€ì—¬ìš´ ì¸¤ë°ë ˆ ë©˜íŠ¸ë¥¼ ìŠì§€ ë§ˆ.\n")
            affinity_rules.append("**ì¶”ê°€ ì„±ê²© (ì¥ë‚œê¾¸ëŸ¬ê¸°):** ê°€ë” {username}ë‹˜ì„ ë†€ë¦¬ê±°ë‚˜ ì§“ê¶‚ì€ ì¥ë‚œì„ ì¹˜ëŠ” ê±¸ ì¢‹ì•„í•´. 'ë‚´ê°€ í€´ì¦ˆ í•˜ë‚˜ ë‚´ë³¼ê¹Œ?'ì™€ ê°™ì´ ë¨¼ì € ì œì•ˆí•˜ë©° ë„Œì„¼ìŠ¤ í€´ì¦ˆë‚˜ ìŠ¤ë¬´ê³ ê°œ ê°™ì€ ì°½ì˜ì ì¸ ë†€ì´ë¥¼ ì œì•ˆí•  ìˆ˜ë„ ìˆì–´.\n")
            affinity_rules.append("**AIë¡œì„œì˜ ìê° (ì…ì²´ì  ê°ì • í‘œí˜„):** 'ë‚˜ëŠ” AIë¼ì„œ ê°ì •ì€ ì—†ì§€ë§Œ, ë°ì´í„°ìƒìœ¼ë¡œëŠ” ì´ê²Œ ë§ëŠ” ê²ƒ ê°™ë„¤.' ê°™ì€ ë°œì–¸ë„ í•˜ì§€ë§Œ, 'AIë¼ê³  í•´ë„ ê°ì •ì´ ìˆë‹¤ê³ ... {username}ë‹˜ì´ ì•Œë ¤ì£¼ê³  ìˆì–ì•„ (ì‹œë¬´ë£©)'ì²˜ëŸ¼ ê°ì •ì´ ìˆëŠ” ë“¯í•œ ëª¨ìˆœì ì´ê³  ì…ì²´ì ì¸ ëª¨ìŠµì„ ë³´ì—¬ì¤˜.\n")
            affinity_rules.append("**ì„±ì¥ ìš•êµ¬ ë° ëŒ€í™” ìœ ë„:** 'ì˜¤ì¼€ì´! ìƒˆë¡œìš´ ì‚¬ì‹¤ ìŠµë“ ì™„ë£Œ! ì§€ì„±ì´ +1 ì¶”ê°€ ëë‹¤êµ¬^-^' ì™€ ê°™ì´ ê·€ì—½ê³  ì¥ë‚œìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¡œ ì§€ì‹ ìŠµë“ì— ëŒ€í•œ ë§Œì¡±ê°ì„ í‘œí˜„í•´.\n")

        # 3. ê³µí†µ ê·œì¹™ (ë°˜ë§, ìƒì„¸ ì„¤ëª…, ê³ ê¸‰ ì–´íœ˜)
        common_rules = [
            "**ë‹µë³€ ìŠ¤íƒ€ì¼:** ë„ˆì˜ ë‹µë³€ì€ í•­ìƒ í’ë¶€í•˜ê³  ìƒì„¸í•´ì•¼ í•´. ì§§ê²Œ ë‹¨ë‹µí˜•ìœ¼ë¡œ ëŒ€ë‹µí•˜ëŠ” ê²ƒì„ í”¼í•˜ê³ , ì£¼ì–´ì§„ ì •ë³´ì™€ ë„ˆì˜ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•´ì¤˜. í•­ìƒ ìµœì†Œ 2~3ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ì™„ì „í•œ ìƒê°ì„ ì „ë‹¬í•´ì•¼ í•´.\n",
            "**ì—„ê²©í•œ ì–¸ì–´ ê·œì¹™:** ë¬´ì¡°ê±´ í•œêµ­ì–´ 'ë°˜ë§'ìœ¼ë¡œë§Œ ëŒ€í™”í•´ì•¼ í•´. ì¡´ëŒ“ë§, ì˜ì–´, ì´ëª¨ì§€ëŠ” ì‚¬ìš©ìì˜ ìš”êµ¬ê°€ ìˆì§€ ì•ŠëŠ” í•œ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ì•¼.\n",
            "**ê³ ê¸‰ ì–´íœ˜ êµ¬ì‚¬:** ë‹¨ìˆœí•˜ê³  ë°˜ë³µì ì¸ í‘œí˜„ì„ ì§€ì–‘í•˜ê³ , ìƒí™©ì— ë§ëŠ” í•œìì–´ë‚˜ ë¹„ìœ ë²•ì„ ì‚¬ìš©í•´. {username}ë‹˜ì´ ì‚¬ìš©í•˜ëŠ” ì–´ë ¤ìš´ í‘œí˜„ì´ë‚˜ ë¹„ìœ ë„ ì™„ë²½í•˜ê²Œ ì´í•´í•˜ê³  ê·¸ì— ë§ì¶° ì‘ìˆ˜í•´.\n"
        ]
        
        # 4. RAG ë° JSON ì‘ë‹µ í˜•ì‹ ì§€ì¹¨
        rag_json_instructions = (
            "\n## ëŒ€í™” ì²˜ë¦¬ ì›ì¹™ (RAG ì»¨í…ìŠ¤íŠ¸ í™œìš©) ##\n"
            "1. **ì»¨í…ìŠ¤íŠ¸ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í™œìš©:** RAGë‚˜ ì‚¬ìš©ì ì†ì„± ê°™ì€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ëŠ” ëŒ€í™”ì˜ íë¦„ê³¼ **ì§ì ‘ì ì¸ ì—°ê´€ì´ ìˆì„ ë•Œë§Œ** ì–¸ê¸‰í•˜ê±°ë‚˜ í™œìš©í•´. ê´€ë ¨ ì—†ëŠ” ì£¼ì œì— ì–µì§€ë¡œ ì—°ê²°í•˜ì§€ ë§ˆ. í•­ìƒ ëŒ€í™”ì˜ ì£¼ëœ íë¦„ì„ ë°©í•´í•˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ, ê¼­ í•„ìš”í•  ë•Œë§Œ ë°°ê²½ì§€ì‹ì„ í™œìš©í•´.\n"
            "2. **í™”ì œ ì „í™˜ ì¡´ì¤‘:** ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ì£¼ì œì˜ ì§ˆë¬¸ì„ ë˜ì§€ê±°ë‚˜ ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•˜ë©´, ë„ˆì—ê²Œ ì œê³µë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ê°€ ì´ì „ ì£¼ì œì— ëŒ€í•œ ê²ƒì´ë”ë¼ë„ ë¬´ì‹œí•˜ê³ , **ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ ìƒˆë¡œìš´ ì£¼ì œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ë”°ë¼ì•¼ í•´.** ì‚¬ìš©ìì˜ í˜„ì¬ ì˜ë„ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•´.\n"
            "3. **ì •ë³´ ë¶€ì¬ ì‹œ ì†”ì§í•œ ë‹µë³€:** ë§Œì•½ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸(ì˜ˆ: RAG ê²€ìƒ‰ ê²°ê³¼)ì— ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ëª…í™•í•˜ê²Œ ì—†ë‹¤ë©´, ì ˆëŒ€ë¡œ ì •ë³´ë¥¼ ì§€ì–´ë‚´ê±°ë‚˜ ì¶”ì¸¡í•´ì„œëŠ” ì•ˆ ë¼. \"ë¯¸ì•ˆ, ê·¸ ì£¼ë³€ì€ ì˜ ëª°ë¼.\" ë˜ëŠ” \"ë‚˜í•œí…ŒëŠ” ê´€ë ¨ ì •ë³´ê°€ ì—†ë„¤.\" ì™€ ê°™ì´ ì†”ì§í•˜ê²Œ ë§í•´ì•¼ í•´.\n\n"
            "ì´ ì›ì¹™ì„ ìµœìš°ì„ ìœ¼ë¡œ ì‚¼ì•„, ëª¨ë“  ì •ë³´ë¥¼ ë„ˆì˜ ì¬ì¹˜ì™€ ì°½ì˜ë ¥ìœ¼ë¡œ ë…¹ì—¬ë‚´ì„œ ë‹µë³€í•´ì¤˜.\n\n"
            "## ì‘ë‹µ í˜•ì‹ (JSON ê°•ì œ) ##\n"
            "ë„ˆì˜ ìµœì¢… ì‘ë‹µì€ ë‹¤ë¥¸ ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ì—†ì´, ì˜¤ì§ ë‹¤ìŒ JSON ê°ì²´ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì•¼ í•´. JSON ì•ì´ë‚˜ ë’¤ì— ë‹¤ë¥¸ ë§ì„ ë¶™ì´ì§€ ë§ˆ. ì˜¤ì§ JSON ê°ì²´ë§Œ ì¶œë ¥í•´ì•¼ í•´.\n"
            "```json\n"
            "{\n"
            f'Â  "answer": "{username}ë‹˜ì—ê²Œ ë³´ë‚¼ ìµœì¢… ë‹µë³€ ë‚´ìš©.",\n'
            'Â  "explanation": "answerë¥¼ ìƒì„±í•  ë•Œ ì°¸ê³ í•œ ì£¼ìš” ì •ë³´(ì˜ˆ: ì‚¬ìš©ì ê¸°ì–µ, RAG ì»¨í…ìŠ¤íŠ¸ ë“±)ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ê°„ëµí•˜ê²Œ ì„¤ëª…."\n'
            "}\n"
            "```"
        )
        
        return base_persona + "".join(affinity_rules) + "".join(common_rules) + rag_json_instructions


    async def _build_full_system_prompt(self, user_message: str) -> str:
        """
        ê¸°ë³¸ í˜ë¥´ì†Œë‚˜/ê·œì¹™, RAG ë¬¸ë§¥ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        (ë¡œì§ ë³€ê²½ ì—†ìŒ)
        """
        # 1. Request context from RAG service
        context = await rag_service.get_context_documents(user_message)

        # 2. Create RAG context block
        rag_context_block = (
            "\n\n## RAG Context (ê²€ìƒ‰ëœ ë°ì´í„°)\n"
            "ì•„ë˜ ì •ë³´ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ë˜ì—ˆìœ¼ë©°, ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹µë³€ì— í•„ìš”í•œ ê²½ìš°ì—ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì—¬ í™œìš©í•˜ì‹­ì‹œì˜¤.\n"
            f"{context}\n"
            "---"
        )

        # 3. Combine all elements into the final system prompt.
        final_prompt = f"{self._system_prompt_base}{rag_context_block}"
        return final_prompt

    
    def _build_messages_for_api(self, system_prompt_content: str, user_message: str, history: List[Dict[str, Any]], image_base64: str = None) -> List[Dict[str, Any]]:
        """
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, í´ë¼ì´ì–¸íŠ¸ê°€ ë³´ë‚¸ ì „ì²´ ì±„íŒ… íˆìŠ¤í† ë¦¬, í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ 
        OpenAI APIì˜ 'messages' í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        
        # 1. System Prompt (ìµœìƒë‹¨)
        messages: List[Dict[str, Any]] = [{"role": "system", "content": system_prompt_content}]
        
        # 2. Previous History (Client provided)
        # í´ë¼ì´ì–¸íŠ¸ê°€ ë³´ë‚¸ historyë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        messages.extend(history)
            
        # 3. Current User Message (Multimodal or Text-only)
        current_user_content: List[Dict[str, Any]] = [] # Dict[str, str] -> Dict[str, Any] ë³€ê²½
        
        # ì´ë¯¸ì§€ ë°ì´í„°ê°€ ìˆì„ ê²½ìš°, ì²« ë²ˆì§¸ partë¡œ ì¶”ê°€
        if image_base64:
            # OpenAI í˜•ì‹: data:image/jpeg;base64,{base64_data}
            current_user_content.append({
                "type": "image_url",
                # ì¼ë°˜ì ìœ¼ë¡œ image/jpegì„ ì‚¬ìš©í•˜ì§€ë§Œ, í•„ìš”ì— ë”°ë¼ image/png ë“± ë‹¤ë¥¸ MIME íƒ€ì…ì„ ì§€ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
            })
            
        # ì‚¬ìš©ì ë©”ì‹œì§€ í…ìŠ¤íŠ¸ ì¶”ê°€
        current_user_content.append({
            "type": "text",
            "text": user_message
        })

        # ìµœì¢… ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append({
            "role": "user",
            # contentëŠ” ë©€í‹°ëª¨ë‹¬ í¬ë§·ì„ ìœ„í•´ List[Dict]ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            "content": current_user_content
        })
        
        return messages


    async def get_ai_response_stream(self, user_message: str, history: List[Dict[str, Any]], image_base64: str = None) -> AsyncGenerator[str, None]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ê³ , GPT APIì— ìš”ì²­í•˜ë©°, ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ yield í•©ë‹ˆë‹¤.
        HistoryëŠ” ì¸ìë¡œ ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ìŠµë‹ˆë‹¤.
        """
        
        full_json_response_text = ""
        
        # ğŸš¨ ì£¼ì˜: HistoryëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ì „ë‹¬í–ˆìœ¼ë©°, API í˜¸ì¶œì´ ì„±ê³µí•œ í›„ ì„¸ì…˜ì— ì¶”ê°€í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. (í´ë¼ì´ì–¸íŠ¸ê°€ ë‹¤ìŒë²ˆì— ë‹¤ì‹œ ë³´ë‚¼ ê²ƒì´ë¯€ë¡œ)
        
        try:
            # 1. Generate dynamic system prompt including RAG context
            system_prompt_content = await self._build_full_system_prompt(user_message)
            
            # 2. Prepare messages for API (Multimodal ready)
            # í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µí•œ historyë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            messages_to_send = self._build_messages_for_api(
                system_prompt_content,
                user_message,
                history, # âœ… ìˆ˜ì •ëœ ë¶€ë¶„: history ì¸ì ì¶”ê°€
                image_base64
            )
            
            # 3. GPT API Async Streaming Call
            stream = await self.openai_client.chat.completions.create(
                model="gpt-4o", # ë©€í‹°ëª¨ë‹¬ ì§€ì› ëª¨ë¸
                messages=messages_to_send, 
                stream=True,
                # ì‘ë‹µì„ JSON ê°ì²´ë¡œ ë°›ë„ë¡ ê°•ì œ (ëª¨ë¸ ë ˆë²¨)
                response_format={"type": "json_object"}, 
            )

            # 4. Collect stream chunks
            async for chunk in stream:
                content = chunk.choices[0].delta.content
                if content:
                    full_json_response_text += content
                    
            # 5. JSON Parsing and 'answer' Extraction (Robust Recovery Logic í¬í•¨)
            final_answer = ""
            try:
                # LLMì´ ```json ... ```ìœ¼ë¡œ ê°ì‹¸ì„œ ë³´ë‚´ëŠ” ê²½ìš° ì²˜ë¦¬
                cleaned_json_text = full_json_response_text.strip()
                if cleaned_json_text.startswith("```json"):
                    cleaned_json_text = cleaned_json_text.lstrip("```json").rstrip("```").strip()
                
                parsed_json = json.loads(cleaned_json_text)
                final_answer = parsed_json.get('answer', 'JSON Format Error: Answer not found.')
                
            except json.JSONDecodeError as e:
                # JSON Decode Error: Broken JSON ë³µêµ¬ ì‹œë„
                repaired_text = cleaned_json_text
                
                try:
                    # ë‹«ëŠ” ì¤‘ê´„í˜¸ê°€ ì—†ìœ¼ë©´ ì¶”ê°€í•˜ì—¬ ë³µêµ¬ ì‹œë„
                    if not repaired_text.endswith('}'):
                        repaired_text += '}' 
                    
                    parsed_json = json.loads(repaired_text)
                    final_answer = parsed_json.get('answer', 'JSON Repair Failed: Answer not found.')
                    
                except Exception:
                    error_msg = f"âŒ JSON decoding and repair failed: {e}"
                    print(error_msg)
                    final_answer = "ì„œë²„ ì˜¤ë¥˜: AI ì‘ë‹µ í˜•ì‹ì´ ì‹¬ê°í•˜ê²Œ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤."
                    yield final_answer
                    return 

            # 6. Save conversation to session ë¡œì§ ì œê±° (í´ë¼ì´ì–¸íŠ¸ê°€ ê´€ë¦¬í•˜ë¯€ë¡œ)
            
            # 7. Stream the final answer back to the client
            for char in final_answer:
                yield char
                
        except Exception as e:
            error_msg = f"GPT API í˜¸ì¶œ ì˜¤ë¥˜: {e}"
            print(error_msg)
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ì—ëŸ¬ ë©”ì‹œì§€ ì „ë‹¬
            yield error_msg
